{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to find it:\\\n",
    "https://github.com/databio/pytorch_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\\\n",
    "https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is [Pytorch](https://pytorch.org/)\n",
    "- PyTorch is an open-source Python library for deep learning developed and maintained by Facebook.\n",
    "- Pytorch is widely used by researchers in the development of new deep learning models and applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check pytorch version\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "# check whether Pytorch supports GPU\n",
    "print(torch.cuda.is_available())\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very basic data structure: [tensor](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "- Tensors are similar to NumPyâ€™s ndarrays, except that tensors can run on *GPUs* or *other hardware accelerators*.\n",
    "- All are tensors: parameters, inputs, and outputs of a model\n",
    "- Optimized for automatic differentiation (generating gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 3., 4.]])\n",
      "cpu\n",
      "torch.float32\n",
      "[[1. 2. 3.]\n",
      " [2. 3. 4.]]\n",
      "float32\n",
      "float64\n",
      "torch.float32\n",
      "GPU not supported\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.0, 2.0, 3.0],[2.0, 3.0, 4.0]])\n",
    "print(a)\n",
    "print(a.device)\n",
    "print(a.dtype)\n",
    "\n",
    "b = a.numpy() # convert a tensor to a numpy array\n",
    "print(b)\n",
    "print(b.dtype)\n",
    "\n",
    "a = np.array([1.0, 2.0, 3.0])\n",
    "print(a.dtype)\n",
    "b = torch.tensor(a, dtype=torch.float32) # the default dtype in Pytorch is torch.float32\n",
    "print(b.dtype)\n",
    "\n",
    "try:\n",
    "    c = a.cuda() # move a to a default GPU, use os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" to specify a default GPU\n",
    "    c = a.to(torch.device('cuda:1')) # move a to GPU #1\n",
    "    d = c.cpu() # move c to CPU (memory)\n",
    "    print(c.device)\n",
    "except:\n",
    "    print(\"GPU not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[2.5000, 4.0000, 5.5000]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.tensor([[0.5, 1.0]])\n",
    "print(d.shape)\n",
    "e = torch.matmul(d, a)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter and [Computation graph](https://pytorch.org/blog/computational-graphs-constructed-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Parameter containing:\n",
      "tensor([0.1000, 0.2000, 0.3000], requires_grad=True)\n",
      "\n",
      "\n",
      "True\n",
      "<DotBackward0 object at 0x7f7b184cda00>\n",
      "None\n",
      "tensor([0.2000, 0.4000, 0.6000])\n"
     ]
    }
   ],
   "source": [
    "#parameter and computation graph\n",
    "a = torch.tensor([0.1,0.2,0.3])\n",
    "print(a.requires_grad)\n",
    "a = nn.Parameter(a)\n",
    "print(a)\n",
    "print('\\n')\n",
    "\n",
    "b = torch.dot(a, a)\n",
    "print(b.requires_grad)\n",
    "print(b.grad_fn)\n",
    "print(a.grad)\n",
    "b.backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare the data.\n",
    "2. Define the model.\n",
    "3. Train the model.\n",
    "4. Evaluate the model.\n",
    "5. Make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch provides the [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class that you can extend and customize to load your dataset.\n",
    "\n",
    "- All datasets that represent a map from keys to data samples should subclass it. \n",
    "\n",
    "- All subclasses should overwrite `__getitem__()`, supporting fetching a data sample for a given key. \n",
    "\n",
    "- Subclasses could also optionally overwrite __len__(), which is expected to return the size of the dataset by many Sampler implementations and the default options of [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "- When loading your dataset, you can also perform any required transforms, such as scaling or encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        \"\"\"Setup the dataset\n",
    "        Need to setup data and labels \n",
    "        [Optional] Set any useful properties, e.g. num_classes for classification\n",
    "        \"\"\"\n",
    "        # store the inputs and outputs\n",
    "        self.data = ...\n",
    "        self.labels = ...\n",
    "        # self.num_classes = 10\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    " \n",
    "    # get an element from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a class that extends the [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class\n",
    "- The constructor of your class defines the layers of the model\n",
    "- Override the `forward()` function to specify how to propagate input through the defined layers of the model\n",
    "- Many layers are available in the [torch.nn](https://pytorch.org/docs/stable/nn.html) module\n",
    "- Activation functions can also be defined as layers or just functions ([torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layer): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model definition\n",
    "class MLP(torch.nn.Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = torch.nn.Linear(n_inputs, 1)\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = self.layer(X)\n",
    "        X = self.activation(X)\n",
    "        return X\n",
    "mlp_model = MLP(10)\n",
    "print(mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                1,\n",
    "                32,\n",
    "                kernel_size=3,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                32,\n",
    "                64,\n",
    "                kernel_size=3,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.conv_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Define an [Optimizer](https://pytorch.org/docs/stable/optim.html#algorithms)\n",
    "- Define a [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "- [Optional] Define a [learning rate scheduler](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n",
    "- Train the model for multiple epochs\n",
    "- Monitor the training status, e.g., loss or accuracy\n",
    "- Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The importance of calling `optimizer.zero_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(2.0)\n",
    "print(a.requires_grad)\n",
    "\n",
    "x = nn.Parameter(torch.tensor(2.0))\n",
    "print(x.requires_grad)\n",
    "y = x * x\n",
    "print(y.grad_fn)\n",
    "y.backward()\n",
    "print(x.grad) # 2*x\n",
    "\n",
    "# go through the computation a second time\n",
    "y = x * x\n",
    "print(y.grad_fn)\n",
    "y.backward()\n",
    "print(x.grad) # the gradient is accumulated!\n",
    "\n",
    "# optimizer.zero_grad() initializes all gradients to None\n",
    "x.grad = None # zero-out the gradient\n",
    "y = x * x\n",
    "print(y.grad_fn)\n",
    "y.backward()\n",
    "print(x.grad) # the gradient is accumulated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300489  [   64/60000]\n",
      "loss: 2.286211  [ 6464/60000]\n",
      "loss: 2.269345  [12864/60000]\n",
      "loss: 2.265061  [19264/60000]\n",
      "loss: 2.246170  [25664/60000]\n",
      "loss: 2.232025  [32064/60000]\n",
      "loss: 2.226007  [38464/60000]\n",
      "loss: 2.202749  [44864/60000]\n",
      "loss: 2.198681  [51264/60000]\n",
      "loss: 2.174844  [57664/60000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.168879  [   64/60000]\n",
      "loss: 2.158053  [ 6464/60000]\n",
      "loss: 2.109062  [12864/60000]\n",
      "loss: 2.124416  [19264/60000]\n",
      "loss: 2.081723  [25664/60000]\n",
      "loss: 2.026275  [32064/60000]\n",
      "loss: 2.048634  [38464/60000]\n",
      "loss: 1.979564  [44864/60000]\n",
      "loss: 1.983211  [51264/60000]\n",
      "loss: 1.919643  [57664/60000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.941796  [   64/60000]\n",
      "loss: 1.911540  [ 6464/60000]\n",
      "loss: 1.805935  [12864/60000]\n",
      "loss: 1.839026  [19264/60000]\n",
      "loss: 1.742735  [25664/60000]\n",
      "loss: 1.686348  [32064/60000]\n",
      "loss: 1.706489  [38464/60000]\n",
      "loss: 1.611423  [44864/60000]\n",
      "loss: 1.632352  [51264/60000]\n",
      "loss: 1.531821  [57664/60000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.609451  [   64/60000]\n",
      "loss: 1.570843  [ 6464/60000]\n",
      "loss: 1.428605  [12864/60000]\n",
      "loss: 1.489096  [19264/60000]\n",
      "loss: 1.380330  [25664/60000]\n",
      "loss: 1.364662  [32064/60000]\n",
      "loss: 1.379982  [38464/60000]\n",
      "loss: 1.304649  [44864/60000]\n",
      "loss: 1.333756  [51264/60000]\n",
      "loss: 1.241772  [57664/60000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.338298  [   64/60000]\n",
      "loss: 1.318971  [ 6464/60000]\n",
      "loss: 1.159138  [12864/60000]\n",
      "loss: 1.255975  [19264/60000]\n",
      "loss: 1.137958  [25664/60000]\n",
      "loss: 1.153104  [32064/60000]\n",
      "loss: 1.178615  [38464/60000]\n",
      "loss: 1.114407  [44864/60000]\n",
      "loss: 1.144662  [51264/60000]\n",
      "loss: 1.074357  [57664/60000]\n",
      "Done!\n",
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    ref = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\" Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the  model\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.089144 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Trouser\", Actual: \"Trouser\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[5][0], test_data[5][1]\n",
    "plt.imshow((x[0].cpu().numpy()*255).astype(np.uint8))\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
